{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCtwzxvvIiNvLpgtx8X2hY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KijoSal-dev/image-classification-tensorflow/blob/main/tnflw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D89Dqv6Iz_gn",
        "outputId": "b0c965f5-1b73-444d-f1ce-bf912fb3e6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8564 - loss: 0.4905\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9564 - loss: 0.1503\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.1061\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.0873\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0715\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07162723690271378, 0.977400004863739]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import TensorFlow. TensorFlow provides the deep learning framework and Keras API for building models.\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset directly from TensorFlow's built-in datasets.\n",
        "# The dataset is automatically downloaded from an online source and split into training and test sets.\n",
        "# x_train and x_test contain image pixel data, while y_train and y_test contain the corresponding digit labels.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values of the images from the original range of 0 to 255 to a range of 0 to 1.\n",
        "# This scaling helps the neural network train faster and more reliably.\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Build a Sequential model, which is a linear stack of layers.\n",
        "model = tf.keras.models.Sequential([\n",
        "    # The Flatten layer converts the 2D 28x28 images into a 1D array of 784 pixels.\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "\n",
        "    # A Dense (fully-connected) layer with 128 neurons and ReLU activation for introducing non-linearity.\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # Dropout layer randomly sets 20% of its inputs to zero during training.\n",
        "    # This prevents overfitting by ensuring that the model does not rely too heavily on any particular set of features.\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    # The final Dense layer with 10 neurons and softmax activation.\n",
        "    # Each neuron corresponds to one of the 10 digits (0-9), and softmax outputs a probability distribution.\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "# - optimizer='adam': Adam optimizer adjusts the learning rate during training.\n",
        "# - loss='sparse_categorical_crossentropy': This loss function is used for integer-labeled classification.\n",
        "# - metrics=['accuracy']: The model will report accuracy during training and testing.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train (fit) the model on the training data over 5 epochs.\n",
        "# An epoch means one full pass through the entire training dataset.\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate the model on the test set.\n",
        "# This provides an unbiased evaluation of how well the model generalizes to new, unseen data.\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb022cd7"
      },
      "source": [
        "# MNIST Image Classification with TensorFlow\n",
        "\n",
        "This notebook demonstrates building and training a simple neural network using TensorFlow and Keras to classify images from the MNIST dataset.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The MNIST dataset is a large database of handwritten digits that is commonly used for training various image processing systems. It consists of 60,000 training images and 10,000 testing images.\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "The model is a sequential neural network with the following layers:\n",
        "\n",
        "1.  **Flatten**: Reshapes the 28x28 pixel images into a 1D array of 784 pixels.\n",
        "2.  **Dense (128 neurons, ReLU activation)**: A fully connected layer with 128 neurons and the Rectified Linear Unit (ReLU) activation function.\n",
        "3.  **Dropout (0.2)**: Randomly sets 20% of the input units to 0 during training to prevent overfitting.\n",
        "4.  **Dense (10 neurons, Softmax activation)**: A fully connected layer with 10 neurons (one for each digit) and the Softmax activation function to output a probability distribution over the classes.\n",
        "\n",
        "## Training\n",
        "\n",
        "The model is compiled with the Adam optimizer and `sparse_categorical_crossentropy` loss function. It is trained for 5 epochs on the training data.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "The model is evaluated on the test data to assess its performance on unseen images. The output of the `evaluate` method shows the loss and accuracy on the test set.\n",
        "\n",
        "## Code\n",
        "\n",
        "The code in this notebook performs the following steps:\n",
        "\n",
        "1.  Imports necessary libraries (TensorFlow).\n",
        "2.  Loads and preprocesses the MNIST dataset (normalization).\n",
        "3.  Defines the sequential neural network model.\n",
        "4.  Compiles the model with an optimizer, loss function, and metrics.\n",
        "5.  Trains the model on the training data.\n",
        "6.  Evaluates the trained model on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jcIvxH5G3Kgo"
      }
    }
  ]
}